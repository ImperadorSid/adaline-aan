{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from load_file import load_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[load_file](https://github.com/ImperadorSid/dotfiles/blob/master/.python-scripts/load_file.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = lambda number: 1 if number >= 0 else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_perceptron = lambda x, w: [signal(w @ sample) for sample in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(x, d, n=0.5, w=[]):\n",
    "  samples = d.shape[0]\n",
    "  inputs = x.shape[1]\n",
    "  epochs = 0\n",
    "\n",
    "  if w == []:\n",
    "    w = np.random.random([1, inputs])\n",
    "    initial_w = np.copy(w)\n",
    "\n",
    "  while True:\n",
    "    error = False\n",
    "    epochs += 1\n",
    "    \n",
    "    for i in range(samples):\n",
    "      u = w @ x[i]\n",
    "      y = signal(u)\n",
    "      if y != d[i]:\n",
    "        w += n * (d[i] - y) * x[i]\n",
    "        error = True\n",
    "        \n",
    "    if not error: break\n",
    "      \n",
    "  return initial_w, w, epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, d = load_csv('../../datasets/petroleo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[petroleo.csv](https://github.com/ImperadorSid/datasets/blob/master/petroleo.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1 - 418 epochs\n",
      "Initial weights: [[0.24394912 0.06925139 0.54511994 0.36482102]]\n",
      "Final weights: [[-3.11605088  1.57216539  2.49771594 -0.74240898]]\n",
      "\n",
      "Training 2 - 455 epochs\n",
      "Initial weights: [[0.80987081 0.93672274 0.469408   0.94248695]]\n",
      "Final weights: [[-3.17012919  1.56648674  2.55856    -0.75697505]]\n",
      "\n",
      "Training 3 - 434 epochs\n",
      "Initial weights: [[0.92826204 0.72040465 0.12597186 0.23730693]]\n",
      "Final weights: [[-3.09173796  1.56373665  2.49663186 -0.73612707]]\n",
      "\n",
      "Training 4 - 400 epochs\n",
      "Initial weights: [[0.3916246  0.04650943 0.44252502 0.79853097]]\n",
      "Final weights: [[-3.0483754   1.54772343  2.46295902 -0.72888703]]\n",
      "\n",
      "Training 5 - 433 epochs\n",
      "Initial weights: [[0.2676866  0.63051339 0.65205756 0.3681343 ]]\n",
      "Final weights: [[-3.1123134   1.57879939  2.50643956 -0.7415137 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "  initial_w, w, epochs = train_perceptron(x, d, n=.01)\n",
    "  print('Training {} - {} epochs\\nInitial weights: {}\\nFinal weights: {}\\n'.format(i, epochs, initial_w, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_weights = np.array([[0.24394912,0.06925139,0.54511994,0.36482102],\n",
    "[0.80987081,0.93672274,0.469408,0.94248695],\n",
    "[0.92826204,0.72040465,0.12597186,0.23730693],\n",
    "[0.3916246,0.04650943,0.44252502,0.79853097],\n",
    "[0.2676866,0.63051339,0.65205756,0.3681343]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
